{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3BhZgBsX9J2"
   },
   "source": [
    "## üìò Introducci√≥n a los LLMs y al Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glosario de Conceptos\n",
    "\n",
    "#### ¬øQu√© es un LLM y c√≥mo funciona?\n",
    "\n",
    "Un **LLM (Large Language Model)** es un modelo de lenguaje basado en aprendizaje profundo, entrenado con grandes vol√∫menes de texto para entender y generar lenguaje humano. Est√° dise√±ado para realizar tareas como:\n",
    "\n",
    "- Completar textos\n",
    "- Traducir idiomas\n",
    "- Responder preguntas\n",
    "- Generar c√≥digo\n",
    "- Resumir contenido\n",
    "\n",
    "Los LLMs se basan principalmente en la **arquitectura Transformer**, donde la atenci√≥n es el mecanismo clave para procesar texto en paralelo y comprender el contexto.\n",
    "\n",
    "**Funcionamiento general:**\n",
    "\n",
    "1. **Input (Prompt):** El usuario proporciona una instrucci√≥n o contexto.\n",
    "2. **Tokenizaci√≥n:** El texto se convierte en tokens (fragmentos de palabras).\n",
    "3. **Procesamiento:** El modelo calcula relaciones entre tokens usando capas de atenci√≥n.\n",
    "4. **Output:** El modelo genera una respuesta (texto, c√≥digo, etc.) como continuaci√≥n l√≥gica del prompt.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Fundamentos del Prompting\n",
    "\n",
    "El **prompting** es el arte de dise√±ar entradas efectivas para obtener respuestas √∫tiles de un modelo LLM. Existen tres enfoques comunes:\n",
    "\n",
    "### ‚úÖ Zero-shot Prompting\n",
    "\n",
    "Consiste en hacer una solicitud directa al modelo **sin proporcionar ejemplos previos**.\n",
    "\n",
    "```text\n",
    "Prompt:\n",
    "\"Resume el siguiente texto en una oraci√≥n.\"\n",
    "```\n",
    "\n",
    "### ‚úÖ Few-shot Prompting\n",
    "Se proporciona al modelo uno o m√°s ejemplos antes de realizar la solicitud. Esto le ayuda a entender el formato o la l√≥gica deseada.\n",
    "\n",
    "```text\n",
    "Prompt:\n",
    "Texto: \"El cielo est√° nublado y podr√≠a llover.\"\n",
    "Resumen: \"Podr√≠a llover pronto.\"\n",
    "\n",
    "Texto: \"Hace calor y hay mucho sol.\"\n",
    "Resumen:\n",
    "```\n",
    "\n",
    "### ‚úÖ Chain-of-Thought (CoT) Prompting\n",
    "Implica pedirle al modelo que razone paso a paso, como si pensara en voz alta. Esto permite respuestas m√°s precisas para tareas de l√≥gica, c√°lculo o an√°lisis.\n",
    "\n",
    "```text\n",
    "Pregunta:\n",
    "Si Mar√≠a tiene 5 manzanas y le da 2 a Juan, ¬øcu√°ntas le quedan?\n",
    "\n",
    "Respuesta:\n",
    "Primero, Mar√≠a tiene 5 manzanas.\n",
    "Luego, le da 2 a Juan.\n",
    "Entonces, le quedan 3 manzanas.\n",
    "```\n",
    "\n",
    "### üî† Tokens, Embeddings y Generaci√≥n de Texto\n",
    "#### üéØ Tokens\n",
    "\n",
    "Los LLMs no procesan texto directamente, sino que lo dividen en tokens, que pueden ser palabras, s√≠labas o incluso fragmentos de palabras.\n",
    "\n",
    "```text\n",
    "Texto: \"Hola mundo\"\n",
    "Tokens: [ \"Hola\", \" mundo\" ]\n",
    "```\n",
    "\n",
    "#### üß¨ Embeddings\n",
    "\n",
    "Cada token se transforma en un vector num√©rico conocido como embedding, que captura informaci√≥n sem√°ntica. Los embeddings permiten al modelo entender similitudes y relaciones entre palabras.\n",
    "\n",
    "####  ‚úçÔ∏è Generaci√≥n de Texto\n",
    "\n",
    "La generaci√≥n de texto se realiza token por token, prediciendo la siguiente palabra m√°s probable seg√∫n el contexto anterior. El resultado final es una secuencia coherente y contextual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9bygXR4W7qL",
    "outputId": "6d872eb1-8684-4238-d16b-d5544223a41a"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from getpass import getpass\n",
    "GEMINI_API_KEY = getpass('Enter API key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rjusJKdYXkKv",
    "outputId": "7e18ef01-b102-4ece-c7b8-5dc247d0fd26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright students, settle down, settle down! Let's talk about a very important tense in English, the **Past Continuous**, also known as the **Past Progressive** or **Past Imperfect**.\n",
      "\n",
      "Think of it as setting the scene in the past. It describes **actions that were in progress at a specific time in the past, or that continued for a period of time in the past.** It's about painting a picture of *what was happening*.\n",
      "\n",
      "**How do we form it?**\n",
      "\n",
      "The structure is simple:\n",
      "\n",
      "**Subject + was/were + verb-ing (present participle)**\n",
      "\n",
      "*   **I/He/She/It + was + verb-ing**\n",
      "*   **You/We/They + were + verb-ing**\n",
      "\n",
      "For example:\n",
      "\n",
      "*   I **was eating** dinner.\n",
      "*   They **were playing** football.\n",
      "*   She **was studying** for her exam.\n",
      "\n",
      "**When do we use the Past Continuous?**  Let's break it down into key situations:\n",
      "\n",
      "**1. Actions in progress at a specific time in the past:**\n",
      "\n",
      "We use the Past Continuous to say what someone was doing at a particular moment. This time can be specified by:\n",
      "\n",
      "*   **A specific time:**  \"At 8 pm last night, I **was watching** a movie.\" (Focus on what I was doing *at that specific time*.)\n",
      "*   **When another action happened (using \"when\" with the Past Simple):** \"I **was walking** to school when I saw an accident.\" (My walking was in progress *when* the accident happened.)\n",
      "*   **During a period of time:** \"They **were living** in France last year.\" (Emphasis on the duration of their stay in France.)\n",
      "\n",
      "**Examples:**\n",
      "\n",
      "*   \"Yesterday at 6 PM, I **was preparing** dinner.\" (Fixed time)\n",
      "*   \"The phone **was ringing** while I **was cooking**.\" (Action interrupting another action)\n",
      "*   \"I **was working** all day yesterday.\" (Period of time)\n",
      "\n",
      "**2. Two or more actions happening at the same time in the past:**\n",
      "\n",
      "Imagine a busy scene. We use the Past Continuous to describe multiple actions occurring simultaneously.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "*   \"While I **was studying**, my brother **was playing** video games and my sister **was listening** to music.\" (All three actions happening at the same time.)\n",
      "\n",
      "**3. Describing a background scene:**\n",
      "\n",
      "Think of setting the stage in a story. The Past Continuous often provides context, painting a picture of what was going on around the main event.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "*   \"The sun **was shining**, the birds **were singing**, and a gentle breeze **was blowing**.  Suddenly, the door slammed shut!\" (The first part sets the scene.)\n",
      "\n",
      "**4. Expressing annoyance or criticism (with \"always,\" \"constantly,\" etc.):**\n",
      "\n",
      "This usage implies that the action is happening more often than desired, and it's annoying the speaker.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "*   \"He **was always complaining** about something.\" (The speaker is annoyed by his constant complaining.)\n",
      "*   \"She **was constantly talking** on the phone.\" (The speaker finds her phone usage excessive.)\n",
      "\n",
      "**Key Signals:**\n",
      "\n",
      "While not always present, some words and phrases often suggest using the Past Continuous:\n",
      "\n",
      "*   **while**\n",
      "*   **as**\n",
      "*   **at (a specific time)**\n",
      "*   **all day/night/morning/year**\n",
      "*   **when (often used with the Past Simple to interrupt the continuous action)**\n",
      "*   **constantly**\n",
      "*   **always**\n",
      "\n",
      "**Common Mistakes to Avoid:**\n",
      "\n",
      "*   **Forgetting \"was/were\":**  \"I eating dinner\" is incorrect. It should be \"I *was* eating dinner.\"\n",
      "*   **Using the Present Continuous instead:**  \"I am watching a movie yesterday\" is incorrect.  Yesterday signals the past.\n",
      "*   **Using Stative verbs in the Continuous:**  Stative verbs (verbs of feeling, thinking, possession, etc.) generally don't take the continuous form. Instead of \"I was knowing,\" you'd say \"I knew.\"\n",
      "\n",
      "**Let's Practice!**\n",
      "\n",
      "Fill in the blanks with the Past Continuous form of the verb:\n",
      "\n",
      "1.  Yesterday at 7 PM, I __________ (read) a book.\n",
      "2.  They __________ (play) football when it started to rain.\n",
      "3.  While she __________ (cook), he __________ (clean) the house.\n",
      "4.  He __________ (always/interrupt) me! It was so annoying.\n",
      "5.  The sun __________ (shine) and the birds __________ (sing).\n",
      "\n",
      "**(Answers below)**\n",
      "\n",
      "So, remember, the Past Continuous paints a picture of ongoing actions in the past. It's about what *was happening* at a specific time or during a period of time.  Practice using it, and you'll become fluent in setting the scene in your English!\n",
      "\n",
      "Any questions?  Don't be afraid to ask!\n",
      "\n",
      "---\n",
      "\n",
      "**Answers to the Practice Exercise:**\n",
      "\n",
      "1.  was reading\n",
      "2.  were playing\n",
      "3.  was cooking, was cleaning\n",
      "4.  was always interrupting\n",
      "5.  was shining, were singing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Configura tu API key (aseg√∫rate de definir GEMINI_API_KEY correctamente antes)\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Usa el modelo correcto\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "# Llama a generate_content correctamente\n",
    "response = model.generate_content(\"Act√∫a como profe de ingl√©s y explica el pasado imperfecto con ejemplos.\")\n",
    "\n",
    "# Imprime el resultado\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLvMao4EZggi"
   },
   "source": [
    "## üß© Modelos LLM Multimodales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¬øQu√© son?\n",
    "\n",
    "Los **LLMs multimodales** son modelos de lenguaje capaces de procesar y generar contenido no solo en texto, sino tambi√©n a partir de otras modalidades como **im√°genes**, **audio** y **video**. Esto permite una interacci√≥n m√°s natural y enriquecida con la inteligencia artificial.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß™ Ejemplos de uso con Gemini\n",
    "\n",
    "- üñºÔ∏è **Descripci√≥n de im√°genes**: interpretar el contenido visual y generar descripciones en lenguaje natural.\n",
    "- üîä **Transcripci√≥n de audio**: convertir voz a texto de manera autom√°tica.\n",
    "- üòä **An√°lisis de sentimiento**: detectar emociones y tono a partir de texto o voz.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚öôÔ∏è Par√°metros importantes\n",
    "\n",
    "Al usar LLMs multimodales, se pueden ajustar varios **par√°metros de configuraci√≥n** para optimizar resultados:\n",
    "\n",
    "- `temperature`: controla la creatividad de las respuestas (valores bajos generan respuestas m√°s precisas).\n",
    "- `model`: selecci√≥n del modelo adecuado (ej. `gemini-2.0-pro`, `gemini-2.0-flash`, etc.).\n",
    "- `max_output_tokens`: define la longitud m√°xima de la respuesta generada.\n",
    "\n",
    "---\n",
    "\n",
    "#### üí° Ventajas clave\n",
    "\n",
    "- Interacci√≥n m√°s rica y contextual.\n",
    "- Permite soluciones inclusivas y accesibles.\n",
    "- Aplicaciones en educaci√≥n, salud, dise√±o, etc.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîó Recurso √∫til\n",
    "\n",
    "- [Gemini Multimodal API](https://aistudio.google.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "id": "dXnrpDwpYS1z",
    "outputId": "8854a53a-c151-4076-e493-8a854ff86e9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Hola! ¬°Me alegra ser tu profe de ingl√©s hoy! Vamos a expandir tu vocabulario de una manera pr√°ctica y divertida. Aqu√≠ te presento algunos ejemplos y estrategias para que empieces a ver resultados:\n",
      "\n",
      "**1. Aprende Palabras en Contexto:**\n",
      "\n",
      "En lugar de memorizar listas de palabras aisladas, aprende c√≥mo se usan en frases y situaciones reales.\n",
      "\n",
      "*   **Ejemplo:** En lugar de solo aprender \"happy,\" busca frases como:\n",
      "    *   \"She was **happy** to receive the good news.\" (Estaba feliz de recibir las buenas noticias.)\n",
      "    *   \"The children were **happily** playing in the park.\" (Los ni√±os estaban jugando felizmente en el parque.)\n",
      "    *   \"He has a **happy** disposition.\" (Tiene una disposici√≥n alegre.)\n",
      "\n",
      "**2. Usa Sin√≥nimos y Ant√≥nimos:**\n",
      "\n",
      "Conocer sin√≥nimos (palabras con significados similares) y ant√≥nimos (palabras con significados opuestos) te ayuda a variar tu lenguaje y a comprender mejor los matices de cada palabra.\n",
      "\n",
      "*   **Ejemplo:**\n",
      "    *   **Palabra:** \"Important\" (Importante)\n",
      "    *   **Sin√≥nimos:** crucial, significant, vital, essential\n",
      "    *   **Ant√≥nimos:** unimportant, insignificant, trivial\n",
      "\n",
      "**3. Aprende Collocations (Combinaciones de Palabras):**\n",
      "\n",
      "Las collocations son combinaciones de palabras que suelen usarse juntas de forma natural. Aprenderlas te ayudar√° a sonar m√°s fluido y natural.\n",
      "\n",
      "*   **Ejemplo:**\n",
      "    *   En lugar de decir \"do a mistake,\" decimos \"make a mistake.\"\n",
      "    *   En lugar de decir \"strong rain,\" decimos \"heavy rain.\"\n",
      "    *   Otros ejemplos: \"take a picture,\" \"have a good time,\" \"do your homework.\"\n",
      "\n",
      "**4. Usa Flashcards (Tarjetas de Memoria):**\n",
      "\n",
      "Las flashcards son una herramienta excelente para memorizar vocabulario. Escribe la palabra en un lado y la definici√≥n y un ejemplo en el otro.\n",
      "\n",
      "*   **Ejemplo:**\n",
      "    *   **Lado 1:** \"Ubiquitous\"\n",
      "    *   **Lado 2:** \"Present, appearing, or found everywhere. Example: Mobile phones are ubiquitous these days.\" (Presente, que aparece o se encuentra en todas partes. Ejemplo\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "response = model.generate_content(\n",
    "    \"Act√∫a como profe de ingl√©s, y dame ejemplos para mejorar vocabulario.\",\n",
    "    generation_config={\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_output_tokens\": 500\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "XBjX4MLrQPcd",
    "outputId": "071238b9-b030-4b10-c856-5ba3e8dbb658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I see a picture of a woman. She is standing in front of two screens. The screens are blue with white frames. On each screen, there is a curved red line and some black dots. The woman looks like she is thinking about what is on the screens. The background is also blue with some light blue shapes.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "image_url = \"https://kinsta.com/es/wp-content/uploads/sites/8/2019/09/jpg-vs-jpeg.jpg\"\n",
    "response = requests.get(image_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "img_byte_arr = BytesIO()\n",
    "img.save(img_byte_arr, format='JPEG')\n",
    "img_bytes = img_byte_arr.getvalue()\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "# Send the prompt with image\n",
    "response = model.generate_content(\n",
    "    [\n",
    "        \"Describe la escena en la imagen usando palabras sencillas para que un estudiante principiante pueda entenderla.\",\n",
    "        {\"mime_type\": \"image/jpeg\", \"data\": img_bytes}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the result\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4s8qxp7dUwMM"
   },
   "source": [
    "## üíª Generaci√≥n de C√≥digo con LLMs\n",
    "\n",
    "### Introducci√≥n\n",
    "\n",
    "Los **Modelos de Lenguaje de Gran Escala (LLMs)** no solo comprenden texto, tambi√©n pueden **generar c√≥digo** en m√∫ltiples lenguajes de programaci√≥n. Gracias a su capacidad de aprender patrones sint√°cticos y sem√°nticos, los LLMs son √∫tiles para tareas como:\n",
    "\n",
    "- Escribir funciones y scripts desde cero\n",
    "- Explicar fragmentos de c√≥digo\n",
    "- Traducir c√≥digo entre lenguajes\n",
    "- Automatizar tareas repetitivas\n",
    "- Resolver problemas paso a paso\n",
    "\n",
    "Uno de los principales beneficios es la **aceleraci√≥n del desarrollo**, especialmente para principiantes o para quienes buscan prototipar r√°pidamente. Sin embargo, es importante **verificar la validez y seguridad** del c√≥digo generado.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Actividad: Traductor palabra por palabra en Python\n",
    "\n",
    "#### Enunciado\n",
    "\n",
    "Usa **Gemini API** para generar un script en Python que:\n",
    "\n",
    "- Reciba como entrada una oraci√≥n en ingl√©s.\n",
    "- Devuelva la traducci√≥n **palabra por palabra** al espa√±ol.\n",
    "- Se asuma que el modelo es un **experto en Python** y proporcione una soluci√≥n funcional y clara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qZxcOeFNUvu9",
    "outputId": "a1a5e52a-08f4-4938-8138-4fb917768caa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "from googletrans import Translator\n",
      "\n",
      "def traducir_oracion(oracion_ingles):\n",
      "  \"\"\"\n",
      "  Traduce una oraci√≥n en ingl√©s al espa√±ol palabra por palabra usando la biblioteca googletrans.\n",
      "\n",
      "  Args:\n",
      "    oracion_ingles: La oraci√≥n en ingl√©s que se va a traducir (string).\n",
      "\n",
      "  Returns:\n",
      "    Una string con la oraci√≥n traducida al espa√±ol palabra por palabra.\n",
      "    Retorna None si hay un error durante la traducci√≥n o si la oraci√≥n est√° vac√≠a.\n",
      "  \"\"\"\n",
      "\n",
      "  if not oracion_ingles:\n",
      "    print(\"Error: La oraci√≥n est√° vac√≠a.\")\n",
      "    return None\n",
      "\n",
      "  try:\n",
      "    translator = Translator()\n",
      "    palabras = oracion_ingles.split()\n",
      "    oracion_traducida = \"\"\n",
      "\n",
      "    for palabra in palabras:\n",
      "      # Traducir cada palabra individualmente\n",
      "      try:\n",
      "        traduccion = translator.translate(palabra, dest='es').text\n",
      "        oracion_traducida += traduccion + \" \"\n",
      "      except Exception as e:\n",
      "        print(f\"Error al traducir la palabra '{palabra}': {e}\")\n",
      "        return None  # Devuelve None si falla la traducci√≥n de alguna palabra\n",
      "    \n",
      "    return oracion_traducida.strip()  # Elimina el espacio final\n",
      "\n",
      "  except Exception as e:\n",
      "    print(f\"Error general durante la traducci√≥n: {e}\")\n",
      "    return None\n",
      "\n",
      "\n",
      "# Ejemplo de uso:\n",
      "oracion_ingles = \"This is a simple sentence to translate.\"\n",
      "oracion_espanol = traducir_oracion(oracion_ingles)\n",
      "\n",
      "if oracion_espanol:\n",
      "  print(f\"Oraci√≥n en ingl√©s: {oracion_ingles}\")\n",
      "  print(f\"Oraci√≥n en espa√±ol (palabra por palabra): {oracion_espanol}\")\n",
      "\n",
      "\n",
      "oracion_ingles_2 = \"Hello world!  How are you today?\"\n",
      "oracion_espanol_2 = traducir_oracion(oracion_ingles_2)\n",
      "\n",
      "if oracion_espanol_2:\n",
      "  print(f\"Oraci√≥n en ingl√©s: {oracion_ingles_2}\")\n",
      "  print(f\"Oraci√≥n en espa√±ol (palabra por palabra): {oracion_espanol_2}\")\n",
      "\n",
      "\n",
      "oracion_ingles_3 = \"\"\n",
      "oracion_espanol_3 = traducir_oracion(oracion_ingles_3)\n",
      "\n",
      "if oracion_espanol_3:\n",
      "  print(f\"Oraci√≥n en ingl√©s: {oracion_ingles_3}\")\n",
      "  print(f\"Oraci√≥n en espa√±ol (palabra por palabra): {oracion_espanol_3}\") #esto no se ejecutar√°\n",
      "\n",
      "oracion_ingles_4 = \"apple banana orange\"\n",
      "oracion_espanol_4 = traducir_oracion(oracion_ingles_4)\n",
      "\n",
      "if oracion_espanol_4:\n",
      "  print(f\"Oraci√≥n en ingl√©s: {oracion_ingles_4}\")\n",
      "  print(f\"Oraci√≥n en espa√±ol (palabra por palabra): {oracion_espanol_4}\")\n",
      "```\n",
      "\n",
      "**Puntos Clave y Explicaci√≥n Detallada:**\n",
      "\n",
      "1. **Importar la Biblioteca:**\n",
      "   - `from googletrans import Translator`:  Importa la clase `Translator` de la biblioteca `googletrans`.  Esta biblioteca es un wrapper para la API de Traducci√≥n de Google.\n",
      "\n",
      "2. **Funci√≥n `traducir_oracion(oracion_ingles)`:**\n",
      "   - Toma una cadena (la oraci√≥n en ingl√©s) como entrada.\n",
      "   - **Manejo de Errores Inicial:** Verifica si la oraci√≥n est√° vac√≠a (`if not oracion_ingles:`). Si lo est√°, imprime un mensaje de error y retorna `None`.  Esto evita que el programa se bloquee si recibe una entrada inesperada.\n",
      "\n",
      "3. **Crear el Traductor:**\n",
      "   - `translator = Translator()`:  Crea una instancia de la clase `Translator`.  Esta instancia se utilizar√° para realizar las traducciones.\n",
      "\n",
      "4. **Dividir la Oraci√≥n en Palabras:**\n",
      "   - `palabras = oracion_ingles.split()`: Divide la oraci√≥n en una lista de palabras, utilizando el espacio en blanco como delimitador.\n",
      "\n",
      "5. **Iterar y Traducir:**\n",
      "   - `for palabra in palabras:`:  Itera sobre cada palabra de la lista `palabras`.\n",
      "   - **Traducci√≥n Individual:**\n",
      "     - `traduccion = translator.translate(palabra, dest='es').text`:  Aqu√≠ es donde se realiza la traducci√≥n.\n",
      "       - `translator.translate(palabra, dest='es')`: Llama al m√©todo `translate` del objeto `translator`.\n",
      "         - `palabra`: La palabra que se va a traducir.\n",
      "         - `dest='es'`: Especifica que el idioma de destino es espa√±ol ('es' es el c√≥digo de idioma ISO 639-1 para espa√±ol).\n",
      "       - `.text`:  Extrae el texto traducido del objeto de respuesta de la API.\n",
      "   - **Construir la Oraci√≥n Traducida:**\n",
      "     - `oracion_traducida += traduccion + \" \"`:  A√±ade la palabra traducida y un espacio a la cadena `oracion_traducida`.\n",
      "   - **Manejo de Errores Dentro del Bucle:**\n",
      "      - `try...except Exception as e:`:  Un bloque `try...except` se incluye dentro del bucle para manejar posibles errores que puedan ocurrir durante la traducci√≥n de una palabra espec√≠fica. Si falla la traducci√≥n de una palabra, se imprime un mensaje de error y la funci√≥n retorna `None`. Esto evita que toda la traducci√≥n falle si hay un problema con una sola palabra.\n",
      "\n",
      "6. **Eliminar Espacio Final y Retornar:**\n",
      "   - `return oracion_traducida.strip()`:  Elimina el espacio en blanco adicional al final de la cadena `oracion_traducida` utilizando el m√©todo `strip()` y retorna la oraci√≥n traducida.\n",
      "\n",
      "7. **Manejo de Errores General:**\n",
      "   - El bloque `try...except` que envuelve todo el proceso de traducci√≥n captura cualquier error inesperado que pueda ocurrir durante la ejecuci√≥n de la funci√≥n. Imprime un mensaje de error si ocurre una excepci√≥n y retorna `None`.\n",
      "\n",
      "8. **Ejemplos de Uso:**\n",
      "   - El c√≥digo incluye varios ejemplos de c√≥mo usar la funci√≥n `traducir_oracion` con diferentes oraciones en ingl√©s, incluyendo una oraci√≥n vac√≠a.  Tambi√©n incluye un `if oracion_espanol:` para asegurarse de que solo se imprima la traducci√≥n si la funci√≥n retorna una cadena v√°lida (es decir, si no hubo errores).\n",
      "\n",
      "**C√≥mo Ejecutar el C√≥digo:**\n",
      "\n",
      "1. **Instalar la Biblioteca `googletrans`:**\n",
      "   ```bash\n",
      "   pip install googletrans==4.0.0-rc1\n",
      "   ```\n",
      "   Es importante usar esta versi√≥n espec√≠fica de `googletrans` ya que las versiones m√°s nuevas tienen problemas de compatibilidad.\n",
      "\n",
      "2. **Guardar el C√≥digo:**\n",
      "   - Guarda el c√≥digo en un archivo Python (por ejemplo, `traductor.py`).\n",
      "\n",
      "3. **Ejecutar el Script:**\n",
      "   ```bash\n",
      "   python traductor.py\n",
      "   ```\n",
      "\n",
      "El script imprimir√° la oraci√≥n original en ingl√©s y la oraci√≥n traducida al espa√±ol (palabra por palabra) en la consola.  Si hay errores, tambi√©n imprimir√° los mensajes de error correspondientes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "response = model.generate_content(\"Eres un experto en python. Escribe un c√≥digo en Python que tome una oraci√≥n en ingl√©s y lo traduzca cada palabra al espa√±ol\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeB63iuYgBuV"
   },
   "source": [
    "### **Prompt Template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kGAMA4vgFxV",
    "outputId": "eba598db-fab2-4511-a943-f5dcd352be4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eres un experto en programaci√≥n, escribiendo c√≥digo limpio en python y escribes comentarios en cada l√≠nea de c√≥digo.\n",
      "a continuaci√≥n, Crea un diccionario.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "Eres un experto en programaci√≥n, escribiendo c√≥digo limpio en python y escribes comentarios en cada l√≠nea de c√≥digo.\n",
    "a continuaci√≥n, {pregunta}.\n",
    "\"\"\"\n",
    "pregunta = \"Crea un diccionario\"\n",
    "prompt = prompt_template.format(pregunta=pregunta)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "JXb7HTRKg3kr",
    "outputId": "a785d2f9-92ef-44b6-ae99-60016c8adec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "# Definimos un diccionario llamado 'mi_diccionario'.\n",
      "# Un diccionario es una estructura de datos que almacena pares clave-valor.\n",
      "mi_diccionario = {}\n",
      "\n",
      "# Agregamos un par clave-valor al diccionario.\n",
      "# La clave es 'nombre' y el valor es 'Juan'.\n",
      "mi_diccionario['nombre'] = 'Juan'\n",
      "\n",
      "# Agregamos otro par clave-valor al diccionario.\n",
      "# La clave es 'edad' y el valor es 30.\n",
      "mi_diccionario['edad'] = 30\n",
      "\n",
      "# Agregamos un tercer par clave-valor al diccionario.\n",
      "# La clave es 'ciudad' y el valor es 'Madrid'.\n",
      "mi_diccionario['ciudad'] = 'Madrid'\n",
      "\n",
      "# Imprimimos el diccionario completo para verificar su contenido.\n",
      "print(mi_diccionario)\n",
      "\n",
      "# Accedemos al valor asociado con la clave 'nombre'.\n",
      "# Esto imprimir√° 'Juan'.\n",
      "print(mi_diccionario['nombre'])\n",
      "\n",
      "# Modificamos el valor asociado con la clave 'edad'.\n",
      "# Cambiamos la edad de 30 a 31.\n",
      "mi_diccionario['edad'] = 31\n",
      "\n",
      "# Imprimimos el diccionario actualizado.\n",
      "print(mi_diccionario)\n",
      "\n",
      "# Eliminamos la clave 'ciudad' y su valor asociado del diccionario.\n",
      "del mi_diccionario['ciudad']\n",
      "\n",
      "# Imprimimos el diccionario despu√©s de eliminar la clave 'ciudad'.\n",
      "print(mi_diccionario)\n",
      "\n",
      "# Verificamos si la clave 'nombre' existe en el diccionario.\n",
      "# Esto imprimir√° True, ya que la clave 'nombre' est√° presente.\n",
      "print('nombre' in mi_diccionario)\n",
      "\n",
      "# Verificamos si la clave 'ciudad' existe en el diccionario.\n",
      "# Esto imprimir√° False, ya que la clave 'ciudad' fue eliminada anteriormente.\n",
      "print('ciudad' in mi_diccionario)\n",
      "\n",
      "# Obtenemos una lista de todas las claves en el diccionario.\n",
      "claves = mi_diccionario.keys()\n",
      "\n",
      "# Imprimimos la lista de claves.\n",
      "print(claves)\n",
      "\n",
      "# Obtenemos una lista de todos los valores en el diccionario.\n",
      "valores = mi_diccionario.values()\n",
      "\n",
      "# Imprimimos la lista de valores.\n",
      "print(valores)\n",
      "\n",
      "# Iteramos a trav√©s del diccionario e imprimimos cada par clave-valor.\n",
      "for clave, valor in mi_diccionario.items():\n",
      "    # Imprimimos la clave y su valor correspondiente.\n",
      "    print(f\"Clave: {clave}, Valor: {valor}\")\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "TNnljWMpi02I",
    "outputId": "4d36a597-4721-4edd-99da-ccee26232ca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claro, como experto en programaci√≥n, escribo c√≥digo limpio y con comentarios detallados en cada l√≠nea seg√∫n tu indicaci√≥n.\n",
      "\n",
      "Aqu√≠ tienes un ejemplo de c√≥mo crear un diccionario simple en Python:\n",
      "\n",
      "```python\n",
      "# Esta l√≠nea define una variable llamada 'mi_diccionario'\n",
      "mi_diccionario = {\n",
      "    # Esta l√≠nea define la primera clave 'clave1' con su valor asociado 'valor1'\n",
      "    'clave1': 'valor1',\n",
      "    # Esta l√≠nea define la segunda clave 'clave2' con su valor asociado 'valor2'\n",
      "    'clave2': 123,\n",
      "    # Esta l√≠nea define la tercera clave 'clave3' con su valor asociado True (booleano)\n",
      "    'clave3': True\n",
      "    # La llave de cierre '}' indica el final de la definici√≥n del diccionario\n",
      "}\n",
      "\n",
      "# Esta l√≠nea opcional imprime el diccionario creado para verificar su contenido\n",
      "print(mi_diccionario)\n",
      "```\n",
      "\n",
      "**Explicaci√≥n:**\n",
      "\n",
      "*   Utilizamos las llaves `{}` para definir un diccionario.\n",
      "*   Dentro de las llaves, cada elemento es un par `clave: valor`.\n",
      "*   Las claves y los valores est√°n separados por dos puntos `:`.\n",
      "*   Los pares `clave: valor` est√°n separados por comas `,`.\n",
      "*   Las claves de un diccionario deben ser inmutables (cadenas, n√∫meros, tuplas, etc.).\n",
      "*   Los valores pueden ser de cualquier tipo de dato.\n",
      "\n",
      "Espero que este ejemplo con comentarios en cada l√≠nea te sea √∫til.\n"
     ]
    }
   ],
   "source": [
    "#Implementaci√≥n de modelo que razona 'experimental gemini 2.0 flash'\n",
    "import google.generativeai as genai\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp')\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gz5abmeQi-ll",
    "outputId": "848ab5d1-a994-4948-d381-4b126866a047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eres un experto en programaci√≥n, escribiendo c√≥digo limpio en python y escribes comentarios en cada l√≠nea de c√≥digo.\n",
      "Explicame este c√≥digo con detalle y como aplicarlo.\n",
      "a continuaci√≥n,\n",
      "{ # Inicia la definici√≥n del diccionario con una llave de apertura {.\n",
      "    \"clave_texto\": \"valor de ejemplo\", # Define el primer par clave-valor: \"clave_texto\" apunta a una cadena.\n",
      "    \"clave_numero\": 123,             # Define el segundo par clave-valor: \"clave_numero\" apunta a un n√∫mero entero.\n",
      "    \"clave_booleano\": True,          # Define el tercer par clave-valor: \"clave_booleano\" apunta a un valor booleano.\n",
      "    \"clave_lista\": [1, 2, 3]         # Define el cuarto par clave-valor: \"clave_lista\" apunta a una lista.\n",
      "} # Cierra la definici√≥n del diccionario con una llave de cierre }.\n",
      ".\n",
      "\n",
      "El resultado deve estar en formato Markdown.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "¬°Claro! Como experto en programaci√≥n Python, con gusto te explico este fragmento de c√≥digo, que representa la definici√≥n de un diccionario. Siempre escribo c√≥digo limpio y con comentarios para que sea f√°cil de entender.\n",
       "\n",
       "Aqu√≠ tienes la explicaci√≥n detallada en formato Markdown:\n",
       "\n",
       "---\n",
       "\n",
       "# Explicaci√≥n Detallada de un Diccionario en Python\n",
       "\n",
       "El fragmento de c√≥digo que has proporcionado es la definici√≥n literal de un **diccionario** en Python. Un diccionario es una colecci√≥n desordenada (en versiones antiguas de Python, ordenada por inserci√≥n en Python 3.7+ y garantizado en 3.8+) de pares **clave-valor**. Cada clave √∫nica est√° asociada a un valor, lo que permite acceder a los valores de manera eficiente utilizando sus claves.\n",
       "\n",
       "Aqu√≠ te muestro el c√≥digo con los comentarios est√°ndar de Python, seguido de la explicaci√≥n:\n",
       "\n",
       "```python\n",
       "# Este es un comentario general que describe lo que hace el bloque de c√≥digo.\n",
       "# Define un diccionario llamado 'mi_diccionario'.\n",
       "mi_diccionario = { # Inicia la definici√≥n del diccionario con la llave de apertura '{'.\n",
       "    \"clave_texto\": \"valor de ejemplo\",  # Primer par clave-valor: 'clave_texto' (cadena) mapea a una cadena. La clave es una cadena, el valor es una cadena.\n",
       "    \"clave_numero\": 123,              # Segundo par clave-valor: 'clave_numero' (cadena) mapea a un n√∫mero entero. La clave es una cadena, el valor es un entero.\n",
       "    \"clave_booleano\": True,           # Tercer par clave-valor: 'clave_booleano' (cadena) mapea a un valor booleano. La clave es una cadena, el valor es booleano.\n",
       "    \"clave_lista\": [1, 2, 3]          # Cuarto par clave-valor: 'clave_lista' (cadena) mapea a una lista. La clave es una cadena, el valor es una lista.\n",
       "} # Finaliza la definici√≥n del diccionario con la llave de cierre '}'.\n",
       "# El punto '.' al final en tu ejemplo original no forma parte de la sintaxis del diccionario en Python; parece un separador de la explicaci√≥n.\n",
       "```\n",
       "\n",
       "## Explicaci√≥n L√≠nea por L√≠nea\n",
       "\n",
       "1.  `# Este es un comentario general...`: Los comentarios que inician con `#` son ignorados por el int√©rprete de Python y se usan para documentar el c√≥digo. Esta l√≠nea es un comentario general sobre el prop√≥sito del bloque.\n",
       "2.  `# Define un diccionario llamado 'mi_diccionario'.`: Otro comentario, especificando que estamos creando un diccionario y asign√°ndolo a una variable llamada `mi_diccionario`.\n",
       "3.  `mi_diccionario = {`: Esta l√≠nea inicia la **definici√≥n del diccionario**.\n",
       "    *   `mi_diccionario =`: Asigna el diccionario que se est√° creando a la variable `mi_diccionario`. Usar una variable es la forma com√∫n de trabajar con un diccionario despu√©s de definirlo.\n",
       "    *   `{`: La llave de apertura `{` indica el comienzo de un diccionario literal.\n",
       "    *   `# Inicia la definici√≥n del diccionario...`: Comentario que describe el significado de la llave `{`.\n",
       "4.  `\"clave_texto\": \"valor de ejemplo\",`: Esta es la definici√≥n del **primer par clave-valor** dentro del diccionario.\n",
       "    *   `\"clave_texto\"`: Es la **clave**. En los diccionarios de Python, las claves suelen ser cadenas (`str`), pero pueden ser cualquier tipo de dato **inmutable** (como n√∫meros, tuplas). Las claves deben ser **√∫nicas** dentro de un mismo diccionario.\n",
       "    *   `: `: El **dos puntos** separa la clave de su valor asociado.\n",
       "    *   `\"valor de ejemplo\"`: Es el **valor** asociado a la clave `\"clave_texto\"`. Los valores pueden ser de **cualquier tipo** de dato en Python (cadenas, n√∫meros, booleanos, listas, otros diccionarios, objetos, etc.).\n",
       "    *   `,`: La **coma** al final de la l√≠nea separa este par clave-valor del siguiente par. No se requiere coma despu√©s del √∫ltimo par.\n",
       "    *   `# Primer par clave-valor...`: Comentario que describe este par espec√≠fico, indicando los tipos de datos de la clave y el valor.\n",
       "5.  `\"clave_numero\": 123,`: **Segundo par clave-valor**.\n",
       "    *   `\"clave_numero\"`: La clave, una cadena.\n",
       "    *   `123`: El valor asociado, un n√∫mero entero (`int`).\n",
       "    *   `# Segundo par clave-valor...`: Comentario descriptivo.\n",
       "6.  `\"clave_booleano\": True,`: **Tercer par clave-valor**.\n",
       "    *   `\"clave_booleano\"`: La clave, una cadena.\n",
       "    *   `True`: El valor asociado, un valor booleano (`bool`).\n",
       "    *   `# Tercer par clave-valor...`: Comentario descriptivo.\n",
       "7.  `\"clave_lista\": [1, 2, 3]`: **Cuarto par clave-valor**.\n",
       "    *   `\"clave_lista\"`: La clave, una cadena.\n",
       "    *   `[1, 2, 3]`: El valor asociado, una lista (`list`). Esto demuestra que los valores pueden ser colecciones u otras estructuras de datos.\n",
       "    *   `# Cuarto par clave-valor...`: Comentario descriptivo.\n",
       "8.  `} # Finaliza la definici√≥n del diccionario...`: La llave de cierre `}` marca el **final** de la definici√≥n del diccionario literal.\n",
       "\n",
       "## C√≥mo Aplicar (Usar) Este Diccionario\n",
       "\n",
       "Una vez que tienes el diccionario definido y asignado a una variable como `mi_diccionario`, puedes interactuar con √©l de diversas maneras:\n",
       "\n",
       "1.  **Acceder a valores:** Usando la clave entre corchetes `[]`.\n",
       "    ```python\n",
       "    # Acceder al valor asociado con \"clave_texto\"\n",
       "    texto = mi_diccionario[\"clave_texto\"] # texto contendr√° \"valor de ejemplo\"\n",
       "    print(texto) # Salida: valor de ejemplo\n",
       "\n",
       "    # Acceder al valor asociado con \"clave_numero\"\n",
       "    numero = mi_diccionario[\"clave_numero\"] # numero contendr√° 123\n",
       "    print(numero) # Salida: 123\n",
       "\n",
       "    # Usar el m√©todo .get() para acceder de forma segura (devuelve None o un valor por defecto si la clave no existe)\n",
       "    valor_seguro = mi_diccionario.get(\"clave_inexistente\", \"Valor por defecto\")\n",
       "    print(valor_seguro) # Salida: Valor por defecto\n",
       "    ```\n",
       "\n",
       "2.  **Modificar valores:** Asignando un nuevo valor a una clave existente.\n",
       "    ```python\n",
       "    # Cambiar el valor de \"clave_numero\"\n",
       "    mi_diccionario[\"clave_numero\"] = 456\n",
       "    print(mi_diccionario[\"clave_numero\"]) # Salida: 456\n",
       "    ```\n",
       "\n",
       "3.  **A√±adir nuevos pares clave-valor:** Asignando un valor a una nueva clave (que no existe en el diccionario).\n",
       "    ```python\n",
       "    # A√±adir un nuevo par\n",
       "    mi_diccionario[\"nueva_clave\"] = \"¬°Hola, mundo!\"\n",
       "    print(mi_diccionario[\"nueva_clave\"]) # Salida: ¬°Hola, mundo!\n",
       "    ```\n",
       "\n",
       "4.  **Eliminar pares clave-valor:** Usando la palabra clave `del` o el m√©todo `.pop()`.\n",
       "    ```python\n",
       "    # Eliminar un par usando del\n",
       "    del mi_diccionario[\"clave_booleano\"]\n",
       "    # print(mi_diccionario[\"clave_booleano\"]) # Esto causar√≠a un error KeyError porque ya no existe\n",
       "\n",
       "    # Eliminar un par usando pop (tambi√©n puedes obtener el valor eliminado)\n",
       "    lista_eliminada = mi_diccionario.pop(\"clave_lista\")\n",
       "    print(lista_eliminada) # Salida: [1, 2, 3]\n",
       "\n",
       "    # pop() tambi√©n permite un valor por defecto si la clave no se encuentra\n",
       "    valor_removido_seguro = mi_diccionario.pop(\"otra_clave\", \"Clave no encontrada\")\n",
       "    print(valor_removido_seguro) # Salida: Clave no encontrada\n",
       "    ```\n",
       "\n",
       "5.  **Iterar sobre el diccionario:** Puedes iterar sobre las claves, los valores o los pares (√≠tems).\n",
       "    ```python\n",
       "    # Iterar sobre las claves\n",
       "    print(\"Claves:\")\n",
       "    for clave in mi_diccionario: # Por defecto, itera sobre las claves\n",
       "        print(clave)\n",
       "\n",
       "    # Iterar sobre los valores\n",
       "    print(\"\\nValores:\")\n",
       "    for valor in mi_diccionario.values():\n",
       "        print(valor)\n",
       "\n",
       "    # Iterar sobre los pares (clave, valor)\n",
       "    print(\"\\nPares (clave, valor):\")\n",
       "    for clave, valor in mi_diccionario.items():\n",
       "        print(f\"{clave}: {valor}\")\n",
       "    ```\n",
       "\n",
       "Este diccionario simple muestra c√≥mo puedes almacenar y acceder a diferentes tipos de datos bajo nombres significativos (las claves). Los diccionarios son incre√≠blemente √∫tiles para representar objetos, configuraciones, registros de datos y mucho m√°s en Python.\n",
       "\n",
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import google.generativeai as genai\n",
    "\n",
    "#Implementaci√≥n de modelo que razona 'experimental gemini 2.0 flash'\n",
    "prompt_template = \"\"\"\n",
    "Eres un experto en programaci√≥n, escribiendo c√≥digo limpio en python y escribes comentarios en cada l√≠nea de c√≥digo.\n",
    "Explicame este c√≥digo con detalle y como aplicarlo.\n",
    "a continuaci√≥n,\n",
    "{codigo}.\n",
    "\n",
    "El resultado deve estar en formato Markdown.\n",
    "\"\"\"\n",
    "\n",
    "codigo = \"\"\"{ # Inicia la definici√≥n del diccionario con una llave de apertura {.\n",
    "    \"clave_texto\": \"valor de ejemplo\", # Define el primer par clave-valor: \"clave_texto\" apunta a una cadena.\n",
    "    \"clave_numero\": 123,             # Define el segundo par clave-valor: \"clave_numero\" apunta a un n√∫mero entero.\n",
    "    \"clave_booleano\": True,          # Define el tercer par clave-valor: \"clave_booleano\" apunta a un valor booleano.\n",
    "    \"clave_lista\": [1, 2, 3]         # Define el cuarto par clave-valor: \"clave_lista\" apunta a una lista.\n",
    "} # Cierra la definici√≥n del diccionario con una llave de cierre }.\n",
    "\"\"\"\n",
    "\n",
    "prompt = prompt_template.format(codigo=codigo)\n",
    "\n",
    "print(prompt)\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp')\n",
    "response = model.generate_content(prompt)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üíª 3. Generaci√≥n de C√≥digo y Hugging Face\n",
    "\n",
    "## üßæ Generaci√≥n y explicaci√≥n de c√≥digo mediante prompts\n",
    "\n",
    "Los **Modelos de Lenguaje de Gran Escala (LLMs)** pueden generar fragmentos de c√≥digo fuente a partir de instrucciones en lenguaje natural. Esto se logra mediante **prompts** bien dise√±ados que indican al modelo qu√© tipo de c√≥digo se desea obtener. Por ejemplo, se puede pedir al modelo:\n",
    "\n",
    "- Que escriba una funci√≥n espec√≠fica.\n",
    "- Que traduzca c√≥digo de un lenguaje a otro.\n",
    "- Que explique paso a paso lo que hace un bloque de c√≥digo.\n",
    "\n",
    "Esta capacidad transforma al LLM en un asistente de programaci√≥n que puede ser √∫til tanto para principiantes como para desarrolladores avanzados.\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ó Uso de la librer√≠a Transformers de Hugging Face\n",
    "\n",
    "La biblioteca **Transformers** de [Hugging Face](https://huggingface.co/transformers/) permite acceder y trabajar con una gran variedad de modelos preentrenados, incluyendo aquellos dise√±ados para tareas de generaci√≥n de c√≥digo como:\n",
    "\n",
    "- `CodeT5`\n",
    "- `StarCoder`\n",
    "- `GPT-2` y `GPT-Neo` con fine-tuning\n",
    "- `Phi`, `CodeGen`, entre otros\n",
    "\n",
    "Caracter√≠sticas clave de la librer√≠a:\n",
    "\n",
    "- Compatibilidad con PyTorch y TensorFlow.\n",
    "- Carga sencilla de modelos y tokenizadores.\n",
    "- Interfaz de alto nivel para inferencia y entrenamiento.\n",
    "- Integraci√≥n con APIs como Google Generative AI, OpenAI o DeepSpeed.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è Ventajas y desaf√≠os del uso de LLMs en programaci√≥n\n",
    "\n",
    "### ‚úÖ Ventajas\n",
    "- **Ahorro de tiempo:** Los desarrolladores pueden generar funciones, scripts y estructuras b√°sicas en segundos.\n",
    "- **Automatizaci√≥n:** Es posible automatizar tareas repetitivas como generaci√≥n de boilerplate, validaciones o transformaciones de datos.\n",
    "- **Soporte educativo:** Ideal para aprender programaci√≥n, entender errores y practicar con ejemplos guiados.\n",
    "\n",
    "### ‚ö†Ô∏è Desaf√≠os\n",
    "- **Alucinaciones:** El modelo puede inventar funciones o estructuras no v√°lidas, incluso si su sintaxis parece correcta.\n",
    "- **Seguridad:** Puede generar c√≥digo vulnerable si no se aplican filtros o validaciones.\n",
    "- **Dependencia excesiva:** Usar el modelo sin entender el c√≥digo puede llevar a una p√©rdida de criterio t√©cnico o errores en producci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJwgYlgppTpZ"
   },
   "source": [
    "### ü§ó **Hugging Face**\n",
    "\n",
    "**Hugging Face** es una plataforma y comunidad de c√≥digo abierto enfocada en la **inteligencia artificial** y el **procesamiento de lenguaje natural (NLP)**. Es ampliamente reconocida por facilitar el acceso a modelos de lenguaje preentrenados y herramientas para desarrolladores, investigadores y entusiastas de la IA.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîß ¬øQu√© ofrece Hugging Face?\n",
    "\n",
    "- **Transformers**: biblioteca en Python para utilizar modelos de lenguaje como BERT, GPT-2, T5, entre otros. Compatible con PyTorch y TensorFlow.\n",
    "- **Model Hub**: repositorio con miles de modelos preentrenados listos para usar.\n",
    "- **Datasets**: colecci√≥n de conjuntos de datos p√∫blicos para entrenamiento y evaluaci√≥n de modelos.\n",
    "- **Spaces**: plataforma para crear y compartir aplicaciones de IA usando Gradio, Streamlit o similares.\n",
    "- **Tokenizers**: herramientas para convertir texto en tokens de forma eficiente, fundamentales en NLP.\n",
    "\n",
    "---\n",
    "\n",
    "#### üí° Aplicaciones comunes\n",
    "\n",
    "- Generaci√≥n de texto\n",
    "- Traducci√≥n autom√°tica\n",
    "- Clasificaci√≥n de sentimientos\n",
    "- Resumen de textos\n",
    "- Chatbots y asistentes virtuales\n",
    "- Pregunta-respuesta (Q&A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273,
     "referenced_widgets": [
      "0ccc2ae765614e9aaf34c48f40375421",
      "578ecf7a7d2344d389b152a6d3036905",
      "53e457df3434488db536480814a1b03e",
      "2378ff77415746519068a1de65e02b1a",
      "d3b23cedadc642e5bbbde60b4d2c8581",
      "04c671463f6f4d4cb389bd61ed779e0e",
      "54b8443a901342f8ab8aa020ca846728",
      "99034464723647f48ad2cbc715b49d34",
      "a018ba96a35549b1986c77eabec92b8e",
      "23bb3ea75e914968ba7c114ad18e3713",
      "0d4d00d727694bb490ea0c45b3a3f6f0",
      "a478a29adc08498f85d4d899a6f58407",
      "61f1c124a6ec464cb6680db3b9872535",
      "1afbd95a439746aebd931e1a1a7d8b21",
      "0ab0c0ae041e46d9a84f3134e4e441e0",
      "26605e6d355643499a81ecb7f322b468",
      "8ec30eea604f40d0bcbcec76ad8969e7",
      "16884da87ccf43d68ddec3b5f4bf7afd",
      "454a366b901e404a9ddcb2c4c8f2731d",
      "61ca41bc070744bb8b80109f940a0f0e",
      "e7486777e83843118ab314dbe1a659c8",
      "0997e80f62664c9fbfea036c4c70d05c",
      "8a0f2f135a604f1f99784dc191f5db2d",
      "7f94bde3531146d68800330145085b1e",
      "0864376745694ab8bd4328429790d8de",
      "bc174ce0429d4fe69a4188d406952f59",
      "5af210c91180461b9f204e1aaee7e229",
      "06de7c3c55fa49cc952bc8e8310d6e8d",
      "cc95e12013b54e97adf1fecf1ef77333",
      "6031f0a1b4f84866a81764250f0331b4",
      "93936a6a76434a6b8a3993135d46c073",
      "70b76aa3741244a9bcb40975f74531c2",
      "159d7bfc9df44d51881c6851ec468713",
      "1493afe283d54a2dafd3786aa6765f37",
      "d28df7965af94e51a2e0c494942b5570",
      "2e163197616e4ad98160a31187c46d15",
      "ea18b2fb22534d069726a61644d3f231",
      "bda9071425534eccb13cf43e4d88f0bd",
      "382359fda38f475c9f2020e292dbe584",
      "08e7cc651e0f4d9b90206747b03b9d49",
      "af14cb58a35f4538b057e53bc4b3f576",
      "0f58d3025ecb473b9a516c8c81fdac83",
      "e0fa8a0f692e4ac4b34a3c0438240efc",
      "58201ceb4e1242bab1e74f73d032b0cb",
      "5e21f2b631e8443bb5dae5f96d1cd9d3",
      "109b2bffa35347c68c894dc7e7ea9793",
      "aa76c48d525b451f96eda1d3d875bf41",
      "c06590bc55e749b7bfc95af4d5f296f1",
      "71346fb33abc489cb289bb2cc01ad7a7",
      "c695d2779214421791075d379ff6b19f",
      "13cd635778384ee7ae0c8aa5e31f279b",
      "5e094fd283084f82ae7b802afd563291",
      "9c2d295c1ca1450082de071c71b0c376",
      "5efdda810e4b48eca04b4d1e37b103a8",
      "c0c52d19a5774862a0d9362b5b2e22ff",
      "fb00581ec86646c4acce2f50d80b72fc",
      "19fe410d7b2141e090dde1b5e9cefcb7",
      "ddfb88e242d0437ca9c37fa93dbcb970",
      "a03231b700844cde8e36c530c80623cc",
      "f81fc3565d0b4a15ad53bf44221f0f8b",
      "2e3e4fe21e0847a9b2d4d713c5f62d51",
      "f07b9c01ffd24e01a4dd6307eb6ca4ce",
      "ed3add80891b4c7496d3c4e362f30efb",
      "d19b2fefcab14930869fd9dfd1b7bb5b",
      "bcd132b892d14079bd00baaebc16e002",
      "be07cd73a87a41f78415c13928f6cc9e",
      "7995e59b0d6244b49bb27c63e1427106",
      "b263c32f854a4a0184ac470412d9fb30",
      "f05a23b67c2a456baab0db8a444b8194",
      "9ccaaf2ac10d4966af1e0eb30bbfd235",
      "e7547457df4e458593224e16f81270ef",
      "88beec7f809b4733bd2a586022afc300",
      "bbd068d28f95421e9875518648771d77",
      "fde5a0b5742a455480d0a6037a58ac9f",
      "2da40b0eb9dc48bd95a9b17a612f603f",
      "c8186504cf3b4359800d487b90748a37",
      "e7a5d76d55964cd1abb6adef05fdb56a",
      "aff3387ff0c9470db08d9624870c6a17",
      "3646bb5b202d415aab510b35a045a06b",
      "e93088944d7f449dba67bb784642791f",
      "36add25e16574327a6f4856ffb9782fe",
      "42d2720d91c141bb8b772792f41e1255",
      "19ce3ce8e38746abbaa26615107534d7",
      "81173987b61048c686cbc9ea16749d9a",
      "b68c3b24030f48978b39215cf1c0958a",
      "4129937471bb4c01a9a85d39b048ab46",
      "bc77cde7a2b4442b955960b095317711",
      "b29460c57ff042cda3c7d02a9ef0ff83"
     ]
    },
    "id": "j90SLXQWpcMr",
    "outputId": "1da031b0-933c-4504-fbbc-75a743d32157"
   },
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NyYbfvx4p_ii"
   },
   "outputs": [],
   "source": [
    "texto_ingles = [\"Hello, how are you?\", \"This is a translation test.\"]\n",
    "tokens = tokenizer(texto_ingles, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6WtSq_hXrzeS",
    "outputId": "85a920f5-c12c-4de9-d65e-ff373b1bd780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hola, ¬øc√≥mo est√°s?', 'Esta es una prueba de traducci√≥n.']\n"
     ]
    }
   ],
   "source": [
    "traduccion_tokens = model.generate(**tokens)\n",
    "traduccion_texto = tokenizer.batch_decode(traduccion_tokens, skip_special_tokens=True)\n",
    "print(traduccion_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8EOs899q7oH",
    "outputId": "a242486e-12cf-4572-e19a-ffca328993f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingl√©s: Hello, how are you? - Espa√±ol: Hola, ¬øc√≥mo est√°s?\n",
      "Ingl√©s: This is a translation test. - Espa√±ol: Esta es una prueba de traducci√≥n.\n"
     ]
    }
   ],
   "source": [
    "for i, t in zip(texto_ingles, traduccion_texto):\n",
    "  print(f\"Ingl√©s: {i} - Espa√±ol: {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XK_K6kI91Ev9"
   },
   "source": [
    "### üîç **RAG (Retrieval-Augmented Generation)**\n",
    "\n",
    "**RAG (Generaci√≥n Aumentada con Recuperaci√≥n)** es una t√©cnica que combina **modelos generativos** (como los LLMs) con un **sistema de recuperaci√≥n de informaci√≥n**. Su objetivo es mejorar las respuestas del modelo accediendo a fuentes de conocimiento externas en tiempo real.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† ¬øC√≥mo funciona?\n",
    "\n",
    "1. **Consulta**: El usuario env√≠a una pregunta o prompt.\n",
    "2. **Recuperaci√≥n**: El sistema busca informaci√≥n relevante en una base de datos o colecci√≥n de documentos (por ejemplo, usando un motor tipo vectorial como FAISS o Elasticsearch).\n",
    "3. **Generaci√≥n**: El modelo LLM usa la informaci√≥n recuperada para generar una respuesta m√°s precisa y actualizada.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìå Caracter√≠sticas clave\n",
    "\n",
    "- No requiere reentrenar el modelo base.\n",
    "- Permite respuestas m√°s **contextualizadas** y **actualizadas**.\n",
    "- Ideal para sistemas que usan datos privados, espec√≠ficos o en constante cambio.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß™ Ejemplos de uso\n",
    "\n",
    "- Asistentes de atenci√≥n al cliente que consultan una base de conocimientos.\n",
    "- Sistemas de recomendaci√≥n basados en documentos.\n",
    "- Aplicaciones empresariales que combinan IA generativa con datos internos.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚öñÔ∏è Ventajas vs Fine-Tuning\n",
    "\n",
    "| RAG                                  | Fine-Tuning                          |\n",
    "|--------------------------------------|--------------------------------------|\n",
    "| Usa documentos externos              | Modifica el modelo base              |\n",
    "| No necesita entrenamiento adicional  | Requiere entrenamiento y c√≥mputo     |\n",
    "| Respuestas actualizadas y din√°micas | Respuestas m√°s coherentes y estables |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FXKDCr1W1N_w"
   },
   "outputs": [],
   "source": [
    "documentos = {\n",
    "    \"IA\": \"La inteligencia artificial es un campo de la inform√°tica que se centra en la creaci√≥n de sistemas capaces de realizar tareas que normalmente requieren inteligencia humana, como reconocer voz, im√°genes, tomar decisiones o resolver problemas.\",\n",
    "    \"RAG\": \"Retrieval-Augmented Generation (RAG) es una t√©cnica de IA que combina b√∫squeda de informaci√≥n en bases de datos o documentos con modelos generativos, permitiendo respuestas m√°s precisas y basadas en conocimiento actualizado.\",\n",
    "    \"Machine Learning\": \"El aprendizaje autom√°tico es una rama de la inteligencia artificial que permite a las computadoras aprender de datos y mejorar su rendimiento sin ser programadas expl√≠citamente para cada tarea.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YCjfwGN61_tb"
   },
   "outputs": [],
   "source": [
    "def recuperar_contexto(pregunta):\n",
    "  for tema, contenido in documentos.items():\n",
    "    if tema.lower() in pregunta.lower():\n",
    "      return contenido\n",
    "    return \"No se encontro informaci√≥n relevante en la base de conocimientos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lIQK1JfH2RcI"
   },
   "outputs": [],
   "source": [
    "def generar_respuesta(pregunta):\n",
    "  contexto = recuperar_contexto(pregunta)\n",
    "  prompt = f\"\"\"Usa el siguiente contexto para responder la pregunta de manera clara y concisa \\n\\n Contexto: {contexto} \\n\\n Pregunta: {pregunta}\"\"\"\n",
    "  genai.configure(api_key=GEMINI_API_KEY)\n",
    "  model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "  response = model.generate_content(prompt)\n",
    "  return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "fPpoyoG2257l",
    "outputId": "bf467fb0-68ce-4e72-f704-e0f04cd3aa0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dado que no hay informaci√≥n en la base de conocimientos, no puedo proporcionar una definici√≥n espec√≠fica de \"RAG\" basada en ella.  Sin acceso a informaci√≥n relevante, solo puedo especular sobre posibles significados o pedir m√°s contexto.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pregunta_usuario = \"Que es RAG\"\n",
    "respuesta = generar_respuesta(pregunta_usuario)\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "g4T_wd7M4A8B",
    "outputId": "019a581a-baa7-40c0-9826-90282ee4c145"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Como no se encontr√≥ informaci√≥n relevante en la base de conocimientos, no puedo decirte qu√© es Cartagena.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pregunta_usuario = \"Que es Cartagena\"\n",
    "respuesta = generar_respuesta(pregunta_usuario)\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ ¬øQu√© es Crew AI?\n",
    "\n",
    "**Crew AI** es un marco de trabajo para crear **agentes de inteligencia artificial colaborativos**, tambi√©n conocidos como *AI agents*, que trabajan juntos como un \"equipo\" (*crew*) para resolver tareas complejas.\n",
    "\n",
    "Cada agente puede tener un rol espec√≠fico (por ejemplo: investigador, planificador, escritor, traductor), y todos operan de forma **coordinada y aut√≥noma** mediante objetivos compartidos, herramientas externas, y comunicaci√≥n entre ellos.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Objetivos clave\n",
    "\n",
    "- **Automatizar flujos de trabajo complejos**\n",
    "- **Descomponer tareas grandes en subtareas distribuidas entre agentes**\n",
    "- **Mejorar la eficiencia y precisi√≥n al combinar diferentes habilidades cognitivas**\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Caracter√≠sticas destacadas\n",
    "\n",
    "- Compatible con **modelos LLM** como GPT-4, Claude o Gemini\n",
    "- Soporte para m√∫ltiples roles con comportamientos personalizados\n",
    "- Capacidad de integraci√≥n con APIs, herramientas externas o fuentes de datos\n",
    "- Ideal para tareas como an√°lisis de datos, redacci√≥n de reportes, investigaci√≥n, planificaci√≥n y m√°s\n",
    "\n",
    "---\n",
    "\n",
    "Crew AI facilita la construcci√≥n de sistemas aut√≥nomos m√°s inteligentes, colaborativos y especializados, siguiendo el enfoque emergente de la **IA multiagente**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Crew Execution Started ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Crew Execution Started</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008080; text-decoration-color: #008080\">crew</span>                                                                                                     <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008080; text-decoration-color: #008080\">c951750a-de70-43ea-8959-08ea0fc54928</span>                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m‚ï≠‚îÄ\u001b[0m\u001b[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[36m Crew Execution Started \u001b[0m\u001b[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[36m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[36m‚îÇ\u001b[0m                                                                                                                 \u001b[36m‚îÇ\u001b[0m\n",
       "\u001b[36m‚îÇ\u001b[0m  \u001b[1;36mCrew Execution Started\u001b[0m                                                                                         \u001b[36m‚îÇ\u001b[0m\n",
       "\u001b[36m‚îÇ\u001b[0m  \u001b[37mName: \u001b[0m\u001b[36mcrew\u001b[0m                                                                                                     \u001b[36m‚îÇ\u001b[0m\n",
       "\u001b[36m‚îÇ\u001b[0m  \u001b[37mID: \u001b[0m\u001b[36mc951750a-de70-43ea-8959-08ea0fc54928\u001b[0m                                                                       \u001b[36m‚îÇ\u001b[0m\n",
       "\u001b[36m‚îÇ\u001b[0m                                                                                                                 \u001b[36m‚îÇ\u001b[0m\n",
       "\u001b[36m‚îÇ\u001b[0m                                                                                                                 \u001b[36m‚îÇ\u001b[0m\n",
       "\u001b[36m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Provider List: https://docs.litellm.ai/docs/providers</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"># Agent:</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Profesor de Ingles</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;95m# Agent:\u001b[0m \u001b[1;92mProfesor de Ingles\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">## Task:</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Explica la diferencia entre los tiempos verbales 'Present Perfect' y 'Past Perfect' con ejemplos</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[95m## Task:\u001b[0m \u001b[92mExplica la diferencia entre los tiempos verbales 'Present Perfect' y 'Past Perfect' con ejemplos\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0f23979bb44f4bbe7d2f249138489a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "import litellm\n",
    "from crewai import Agent, Task, Crew, LLM\n",
    "\n",
    "### Definir los agentes\n",
    "profesor = Agent(\n",
    "    role=\"Profesor de Ingles\",\n",
    "    goal=\"Explicar conceptos de gram√°tica y vocabulario en Ingl√©s de manera clara y efectiva\",\n",
    "    backstory=\"Eres un profesor con experiencia en ense√±ar ingl√©s a estudiantes de todos los niveles\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm={\n",
    "        \"model\": \"gemini/gemini-2.0-flash\",\n",
    "        \"api_key\": GEMINI_API_KEY\n",
    "    }\n",
    ")\n",
    "\n",
    "evaluador = Agent(\n",
    "    role=\"Evaluador de Ingles\",\n",
    "    goal=\"Dise√±ar preguntas de evaluaci√≥n y revisar las respuestas del estudiante.\",\n",
    "    backstory=\"Eres un experto en pruebas de ingl√©s y puedes dar retroalimentaci√≥n detallada\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm={\n",
    "        \"model\": \"gemini/gemini-2.0-flash\",\n",
    "        \"api_key\": GEMINI_API_KEY\n",
    "    }\n",
    ")\n",
    "\n",
    "### Definici√≥n de tarea de los agentes\n",
    "explicacion_ingles = Task(\n",
    "    description = \"Explica la diferencia entre los tiempos verbales 'Present Perfect' y 'Past Perfect' con ejemplos\",\n",
    "    expected_output=\"Una explicaxi√≥n clara y ejemplos concretos\",\n",
    "    agent = profesor\n",
    ")\n",
    "\n",
    "evaluacion_ingles = Task(\n",
    "    description = \"Crea un Test de 3 preguntas basado en la explicaci√≥n dada por el profesor\",\n",
    "    expected_output=\"Un test de 3 preguntas con sus respuestas correctas, relacionado con la diferencia entre 'Present perfect' y 'Past Perfect'\",\n",
    "    agent = evaluador\n",
    ")\n",
    "\n",
    "# Definir el Crew\n",
    "crew = Crew(\n",
    "    agents=[profesor, evaluador],\n",
    "    tasks=[explicacion_ingles, evaluacion_ingles],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Ejecutar el Crew\n",
    "resultado = crew.kickoff()\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
