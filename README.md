# Bootcamp de Prompt Engineering

##  Descripci贸n

Este repositorio contiene materiales de apoyo y herramientas pr谩cticas relacionadas con el **Prompt Engineering** y el uso de **Modelos de Lenguaje de Gran Escala (LLMs)**.

Est谩 basado en el contenido impartido por **Lesly Zerna**, Google Developer Expert en Inteligencia Artificial.

El objetivo principal es comprender c贸mo interactuar con modelos de lenguaje utilizando t茅cnicas efectivas de prompting, as铆 como explorar capacidades avanzadas como generaci贸n de c贸digo, interacci贸n multimodal y personalizaci贸n de modelos mediante Fine-Tuning y RAG (Retrieval-Augmented Generation).

---

##  Temas Principales

### 1. Introducci贸n a los LLMs y el Arte del Prompting
- Qu茅 es un LLM y c贸mo funciona.
- Fundamentos del prompting:  
  - **Zero-shot prompting**
  - **Few-shot prompting**
  - **Chain-of-Thought (CoT)**
- Comprensi贸n de tokens, embeddings y generaci贸n de texto.

### 2. Modelos LLM Multimodales
- Modelos capaces de procesar **texto, im谩genes y audio**.
- Ejemplos de uso con Gemini:
  - Descripci贸n de im谩genes.
  - Transcripci贸n de audio.
  - An谩lisis de sentimiento.
- Consideraciones sobre par谩metros como temperatura y modelo.

### 3. Generaci贸n de C贸digo y Hugging Face
- C贸mo generar y explicar c贸digo a trav茅s de prompts.
- Uso de la librer铆a **Transformers** de Hugging Face.
- Ventajas y desaf铆os del uso de LLMs para programaci贸n:
  - Ahorro de tiempo
  - Automatizaci贸n de tareas
  - Riesgos como alucinaciones o generaci贸n de c贸digo inseguro

### 4. Fine-Tuning y RAG (Retrieval-Augmented Generation)
- Personalizaci贸n de modelos LLM con datos espec铆ficos.
- Diferencias entre **Fine-Tuning** y **RAG**:
  - Fine-Tuning: entrenamiento adicional del modelo.
  - RAG: recuperaci贸n de informaci贸n relevante desde fuentes externas sin modificar el modelo base.
- Casos de uso, ventajas y desventajas de cada enfoque.

---

## О Dependencias y versiones

Este proyecto utiliza las siguientes versiones de Python y bibliotecas:

```toml
python = ">=3.11.11,<3.13"
google-generativeai = "^0.8.5"
google-genai = "^1.16.1"
googletrans = "^4.0.2"
transformers = "^4.52.3"
sacremoses = "^0.1.1"
pillow = "^11.2.1"
requests = "^2.32.3"
sentencepiece = "^0.2.0"
torch = "^2.7.0"
ipywidgets = "^8.1.7"
litellm = "1.68.0"
crewai = "^0.121.0"